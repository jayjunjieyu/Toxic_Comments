{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id    target                                       comment_text  \\\n",
      "458232    806064  0.000000  It's difficult for many old people to keep up ...   \n",
      "272766    576402  0.166667  She recognized that her tiny-handed husband is...   \n",
      "339129    658508  0.000000  HPHY76,\\nGood for you for thinking out loud, w...   \n",
      "773565   5066714  0.500000  And I bet that in the day you expected your Je...   \n",
      "476233    828147  0.000000  Kennedy will add a much needed and scientifica...   \n",
      "317668    631532  0.300000  Yeah, because it is far more important to pres...   \n",
      "839167   5147509  0.000000          Housing inmates is a profitable business.   \n",
      "913935   5237995  0.000000                                           Go Sens!   \n",
      "904703   5226678  0.200000  Lol...sounds like someone IS brainwashed but I...   \n",
      "1579488  6054559  0.000000  Tax relief should include commercial real esta...   \n",
      "\n",
      "         severe_toxicity  obscene  identity_attack    insult  threat  asian  \\\n",
      "458232               0.0      0.0              0.0  0.000000     0.0    NaN   \n",
      "272766               0.0      0.0              0.0  0.166667     0.0    NaN   \n",
      "339129               0.0      0.0              0.0  0.000000     0.0    NaN   \n",
      "773565               0.0      0.0              0.4  0.100000     0.0    0.0   \n",
      "476233               0.0      0.0              0.0  0.000000     0.0    NaN   \n",
      "317668               0.0      0.1              0.2  0.100000     0.0    NaN   \n",
      "839167               0.0      0.0              0.0  0.000000     0.0    NaN   \n",
      "913935               0.0      0.0              0.0  0.000000     0.0    NaN   \n",
      "904703               0.0      0.0              0.0  0.200000     0.0    NaN   \n",
      "1579488              0.0      0.0              0.0  0.000000     0.0    NaN   \n",
      "\n",
      "         atheist  ...    rating  funny  wow  sad  likes  disagree  \\\n",
      "458232       NaN  ...  approved      0    0    0      1         0   \n",
      "272766       NaN  ...  approved      0    0    0      2         0   \n",
      "339129       NaN  ...  approved      0    0    0      0         0   \n",
      "773565       0.0  ...  approved      0    0    0      4         2   \n",
      "476233       NaN  ...  approved      0    0    1      0         0   \n",
      "317668       NaN  ...  approved      0    0    0      0         0   \n",
      "839167       NaN  ...  approved      0    0    0      0         0   \n",
      "913935       NaN  ...  approved      0    0    0      0         0   \n",
      "904703       NaN  ...  approved      1    0    1      6         2   \n",
      "1579488      NaN  ...  rejected      0    0    0      0         0   \n",
      "\n",
      "         sexual_explicit  identity_annotator_count  toxicity_annotator_count  \\\n",
      "458232               0.0                         0                         4   \n",
      "272766               0.0                         0                         6   \n",
      "339129               0.0                         0                         4   \n",
      "773565               0.0                         6                        10   \n",
      "476233               0.0                         0                         4   \n",
      "317668               0.1                         0                        10   \n",
      "839167               0.0                         0                         4   \n",
      "913935               0.0                         0                         4   \n",
      "904703               0.0                         0                        10   \n",
      "1579488              0.0                         0                         4   \n",
      "\n",
      "             LSTM  \n",
      "458232   0.009145  \n",
      "272766   0.449597  \n",
      "339129   0.007944  \n",
      "773565   0.466427  \n",
      "476233   0.006946  \n",
      "317668   0.060199  \n",
      "839167   0.011535  \n",
      "913935   0.008754  \n",
      "904703   0.304611  \n",
      "1579488  0.004763  \n",
      "\n",
      "[10 rows x 46 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Float64Index([nan, nan, nan, 0.0, nan, nan, nan, nan, nan, nan,\\n              ...\\n              0.0, nan, nan, nan, nan, nan, nan, nan, 0.0, nan],\\n             dtype='float64', length=20000)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-06c0b07a62f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'subgroup_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m \u001b[0mbias_metrics_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_bias_metrics_for_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidate_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midentity_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTOXICITY_COLUMN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m# Calculate the final score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-06c0b07a62f7>\u001b[0m in \u001b[0;36mcompute_bias_metrics_for_model\u001b[1;34m(dataset, subgroups, model, label_col, include_asegs)\u001b[0m\n\u001b[0;32m     57\u001b[0m         record = {\n\u001b[0;32m     58\u001b[0m             \u001b[1;34m'subgroup'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msubgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[1;34m'subgroup_size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubgroup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         }\n\u001b[0;32m     61\u001b[0m         \u001b[0mrecord\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSUBGROUP_AUC\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_subgroup_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1244\u001b[0m                 raise KeyError(\n\u001b[0;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1246\u001b[1;33m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Float64Index([nan, nan, nan, 0.0, nan, nan, nan, nan, nan, nan,\\n              ...\\n              0.0, nan, nan, nan, nan, nan, nan, nan, 0.0, nan],\\n             dtype='float64', length=20000)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "validate_df = pd.read_csv('train.csv').sample(20000,random_state=1234)\n",
    "\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "TOXICITY_COLUMN = 'target'\n",
    "TEXT_COLUMN = 'comment_text'\n",
    "MODEL_NAME = \"LSTM\"\n",
    "validate_df[MODEL_NAME] = pd.read_pickle('val_pred_lstm')\n",
    "\n",
    "print(validate_df.head(n=10))\n",
    "\n",
    "# Define bias metrics\n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset[dataset[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "bias_metrics_df = compute_bias_metrics_for_model(validate_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "\n",
    "# Calculate the final score\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "    \n",
    "get_final_metric(bias_metrics_df, calculate_overall_auc(validate_df, MODEL_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
